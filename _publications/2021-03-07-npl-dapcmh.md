---
title: "DAPCMH: Deep Adversarial Privacy-Preserving Cross-Modal Hashing"
collection: publications
permalink: /publication/2021-03-07-npl-dapcmh
excerpt: 'Cross-Modal Hashing; Multimodal Learning'
date: 2021-March-07
venue: 'Neural Processing Letters'
paperurl: 'https://link.springer.com/article/10.1007/s11063-021-10447-4'
citation: 'Lei Zhu, Jiayu Song, Zhan Yang, Wenti Huang, Chengyuan Zhang, Weiren Yu, DAPCMH: Deep Adversarial Privacy-Preserving Cross-Modal Hashing, Neural Processing Letters, 2022, 54(4): 2549-2569'
---

Privacy-preserving cross-modal retrieval is a significant problem in the area of multimedia analysis. As the amount of data is exploding, cross-modal data analysis and retrieval is often realized on cloud computing environment. Therefore, the privacy protection of large-scale cross-modal data has become a problem that can not be ignored. To further improve the accuracy and efficiency of privacy-preserving search, this paper proposes a novel cross-modal hashing scheme, named deep adversarial privacy-preserving cross-modal hashing (DAPCMH). This method consists of a deep cross-modal hashing model termed DACMH, and a secure index structure called CMH-Tree. The former is a combination of deep hashing and adversarial learning to capture intra-modal and inter-modal correlation. The latter is a hierarchical hashing index structure that can provide efficient data organization based on cross-modal hash codes. We conduct comprehensive experiments on three common used benchmarks. The results show that the proposed approach DAPCMH outperforms the state-of-the-arts.
